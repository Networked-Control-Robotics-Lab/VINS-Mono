%YAML:1.0

#common parameters
imu_topic: "/imu/data_raw"
image_topic: "/arducam/triggered/camera/image_raw"
output_path: "/home/nvidia/catkin_ws/src/VINS-Mono/support_files"

#camera calibration 
model_type: PINHOLE
camera_name: camera
#AR0134_M25360H06
image_width: 640
image_height: 484
distortion_parameters:
   k1: -0.347793
   k2: 0.107340
   k3: 0.000722
   k4: -0.001039
projection_parameters:
   fx: 409.55
   fy: 409.27
   cx: 302.513
   cy:  239.733
#distortion_parameters:
#   k1: -0.0627294903336975
#   k2: 0.037315397599265554
#   k3: -0.1143889971297141
#   k4: 0.08159696210350505
#projection_parameters:
#   fx: 417.65449023780224   
#   fy: 417.14577671559465
#   cx: 302.298042718092
#   cy:  239.84639385325715 
#MT9v034_LS301188
#image_width: 640
#image_height: 480
#distortion_parameters:
#   k1: -0.35756
#   k2: 0.11909
#   p1: -0.001066
#   p2: -0.001789
#projection_parameters:
#   fx: 450.946511
#   fy: 453.592795
#   cx: 297.75849
#   cy: 255.72969

# Extrinsic parameter between IMU and Camera.
estimate_extrinsic: 1   # 0  Have an accurate extrinsic parameters. We will trust the following imu^R_cam, imu^T_cam, don't change it.
                        # 1  Have an initial guess about extrinsic parameters. We will optimize around your initial guess.
                        # 2  Don't know anything about extrinsic parameters. You don't need to give R,T. We will try to calibrate it. Do some rotation movement at beginning.                        
#If you choose 0 or 1, you should write down the following matrix.
#Rotation from camera frame to imu frame, imu^R_cam
extrinsicRotation: !!opencv-matrix
   rows: 3
   cols: 3
   dt: d
   #data: [ 3.5547377966504534e-02, -9.9819308302994181e-01,
    #   -4.8445360055281682e-02, 9.9855985185796758e-01,
     #  3.3527772724371241e-02, 4.1882104932016398e-02,
      # -4.0182162424389177e-02, -4.9864390574059170e-02,
       #9.9794736152543517e-01 ]
#   data: [ -0.02222599 , -0.0301788, 0.99929738,
#        -0.99968395, -0.01107458, -0.02256904,
#        0.01174791, -0.99948316, -0.02992312 ]
   data: [ 0.99979351 , 0.00695551 , 0.01909363,
        -0.01908388 , -0.00146462 , 0.99981681,
        0.0069822 , -0.99997474 , -0.00133158  ]

#Translation from camera frame to imu frame, imu^T_cam
extrinsicTranslation: !!opencv-matrix
   rows: 3
   cols: 1
   dt: d
   data: [ 0.0 , 0.06 , -0.0489398 ]

#feature traker paprameters
max_cnt: 100            # max feature number in feature tracking
min_dist: 25            # min distance between two features 
freq: 10                # frequence (Hz) of publish tracking result. At least 10Hz for good estimation. If set 0, the frequence will be same as raw image 
F_threshold: 1.0        # ransac threshold (pixel)
show_track: 1           # publish tracking image as topic

#optimization parameters
max_solver_time: 0.04  # max solver itration time (ms), to guarantee real time
max_num_iterations: 8   # max solver itrations, to guarantee real time
keyframe_parallax: 10.0 # keyframe selection threshold (pixel)

#imu parameters       The more accurate parameters you provide, the better performance
#acc_n: 0.08          # accelerometer measurement noise standard deviation. #0.2   0.04
#gyr_n: 0.004         # gyroscope measurement noise standard deviation.     #0.05  0.004
acc_n: 0.2         # accelerometer measurement noise standard deviation. #0.2   0.04
gyr_n: 0.02       # gyroscope measurement noise standard deviation.     #0.05  0.004
acc_w: 0.02        # accelerometer bias random work noise standard deviation.  #0.02
gyr_w: 4.0e-5       # gyroscope bias random work noise standard deviation.     #4.0e-5
g_norm: 9.81    # gravity magnitude

#loop closure parameters
loop_closure: 1                    # start loop closure
fast_relocalization: 1            # useful in real-time and large project
load_previous_pose_graph: 0        # load and reuse previous pose graph; load from 'pose_graph_save_path'
pose_graph_save_path: "/home/nvidia/catkin_ws1/src/VINS-Mono/support_files" # save and load path

#unsynchronization parameters
estimate_td: 1                      # online estimate time offset between camera and imu
td: -0.038                          # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)

#rolling shutter parameters
rolling_shutter: 0                  # 0: global shutter camera, 1: rolling shutter camera
rolling_shutter_tr: 0               # unit: s. rolling shutter read out time per frame (from data sheet). 

#visualization parameters
save_image: 1                   # save image in pose graph for visualization prupose; you can close this function by setting 0 
visualize_imu_forward: 1        # output imu forward propogation to achieve low latency and high frequence results
visualize_camera_size: 0.4      # size of camera marker in RVIZ
